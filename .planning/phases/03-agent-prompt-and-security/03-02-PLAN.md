---
phase: 03-agent-prompt-and-security
plan: 02
type: execute
wave: 2
depends_on:
  - 03-01
files_modified:
  - src/agent/bead-runner.ts
  - src/agent/code-agent-runner.ts
  - tests/unit/code-agent-runner.test.ts
autonomous: true
requirements:
  - AGENT-05
  - AGENT-08

must_haves:
  truths:
    - "The pipeline produces NO_IMPROVEMENT when no meaningful change is found for any category, after trying all fallback categories"
    - "GITLAB_TOKEN is only forwarded to the MR bead via env option — other beads receive a sanitized env without the token"
    - "The Implement bead retries up to 2 times (3 total attempts) after Verify failure, with git reset --hard between retries"
    - "The notification reflects the actual category used, including fallback notation when applicable"
    - "The pipeline produces MR_CREATED with the MR URL when the full bead sequence succeeds"
  artifacts:
    - path: "src/agent/bead-runner.ts"
      provides: "Single bead invocation with env isolation, tool restriction, model selection"
      exports: ["runBead", "buildBeadEnv", "buildBeadArgs"]
    - path: "src/agent/code-agent-runner.ts"
      provides: "4-bead pipeline orchestrator with retry and category fallback"
      exports: ["runCodeAgentPipeline"]
    - path: "tests/unit/code-agent-runner.test.ts"
      provides: "Tests for pipeline orchestration, fallback, retry, token isolation, NO_IMPROVEMENT"
      min_lines: 80
  key_links:
    - from: "src/agent/code-agent-runner.ts"
      to: "src/agent/bead-runner.ts"
      via: "runBead calls for each pipeline step"
      pattern: "runBead\\("
    - from: "src/agent/code-agent-runner.ts"
      to: "src/agent/prompt-loader.ts"
      via: "loadBeadPrompt for each bead's prompt"
      pattern: "loadBeadPrompt\\("
    - from: "src/agent/bead-runner.ts"
      to: "src/utils/process.ts"
      via: "spawnWithTimeout for claude -p invocation"
      pattern: "spawnWithTimeout\\("
    - from: "src/agent/bead-runner.ts"
      to: "GITLAB_TOKEN env var"
      via: "buildBeadEnv selectively includes token only for mr bead"
      pattern: "GITLAB_TOKEN"
---

<objective>
Build the code-agent execution pipeline: a bead-runner for individual Claude CLI invocations with env isolation, and a code-agent-runner that orchestrates the 4-bead sequence (Analyze -> Implement -> Verify -> MR) with retry logic and category fallback.

Purpose: This is the runtime engine that executes the prompts created in Plan 01. It enforces the critical security invariant (GITLAB_TOKEN only in MR bead env), implements the category fallback order (tests -> refactoring -> docs -> security -> performance), handles Implement retries after Verify failures, and produces the final CodeAgentRunResult consumed by the orchestrator and notification system.

Output: bead-runner module, code-agent-runner module, comprehensive tests.
</objective>

<execution_context>
@/Users/julienderay/.claude/get-shit-done/workflows/execute-plan.md
@/Users/julienderay/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-agent-prompt-and-security/03-CONTEXT.md
@.planning/phases/03-agent-prompt-and-security/03-RESEARCH.md
@.planning/phases/03-agent-prompt-and-security/03-01-SUMMARY.md
@src/agent/types.ts
@src/agent/prompt-loader.ts
@src/core/config.ts
@src/core/types.ts
@src/utils/process.ts
@src/daemon/agent-runner.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create bead-runner with env isolation and tool restriction</name>
  <files>
    src/agent/bead-runner.ts
  </files>
  <action>
Create `src/agent/bead-runner.ts` — a module for running a single Claude CLI bead invocation.

**`buildBeadEnv` function:**

Constructs a sanitized environment for each bead. Start with a minimal safe env (HOME, PATH, USER, LANG, SHELL, TERM) from `process.env`. Only the "mr" bead gets `GITLAB_TOKEN`:

```typescript
export function buildBeadEnv(
  beadName: "analyze" | "implement" | "verify" | "mr",
  gitlabToken: string | undefined,
): NodeJS.ProcessEnv {
  const safeEnv: NodeJS.ProcessEnv = {
    HOME: process.env.HOME,
    PATH: process.env.PATH,
    USER: process.env.USER,
    LANG: process.env.LANG,
    SHELL: process.env.SHELL,
    TERM: process.env.TERM,
  };
  if (beadName === "mr" && gitlabToken) {
    safeEnv.GITLAB_TOKEN = gitlabToken;
  }
  return safeEnv;
}
```

This is the AGENT-08 enforcement point. GITLAB_TOKEN is NEVER in the args array, NEVER in the prompt string — only in the env object for the mr bead.

**`buildBeadArgs` function:**

Constructs the Claude CLI argument array for a bead invocation:

```typescript
export function buildBeadArgs(
  prompt: string,
  model: string,
  maxTokens?: number,
): string[] {
  const args = [
    "-p", prompt,
    "--output-format", "json",
    "--dangerously-skip-permissions",
    "--no-session-persistence",
    "--allowedTools", "Bash", "Read", "Write",
    "--model", model,
  ];
  if (maxTokens !== undefined) {
    args.push("--max-budget-usd", maxTokens.toString());
  }
  return args;
}
```

Note: `--allowedTools` values are separate array elements (consistent with existing `AgentRunner.buildArgs` pattern in agent-runner.ts). This enforces AGENT-09 — only Bash, Read, Write tools are available.

**`runBead` function:**

Wraps `spawnWithTimeout` to run a single bead:

```typescript
export async function runBead(options: {
  beadName: "analyze" | "implement" | "verify" | "mr";
  prompt: string;
  model: string;
  cwd: string;
  timeoutMs: number;
  gitlabToken?: string;
  maxTokens?: number;
}): Promise<BeadResult> {
  const env = buildBeadEnv(options.beadName, options.gitlabToken);
  const args = buildBeadArgs(options.prompt, options.model, options.maxTokens);
  const { result } = spawnWithTimeout("claude", args, {
    timeoutMs: options.timeoutMs,
    cwd: options.cwd,
    env,
  });
  const spawnResult = await result;
  // Parse the JSON output from claude -p
  // Extract cost, duration from ClaudeJsonOutput
  // Return BeadResult
}
```

Parse stdout as `ClaudeJsonOutput` (from `src/core/types.ts`). On parse failure or non-zero exit, populate BeadResult with error info but do NOT throw — the pipeline orchestrator decides how to handle errors.

Import `spawnWithTimeout` from `../utils/process.js` and `BeadResult` from `./types.js`.

**Anti-patterns to avoid:**
- NEVER pass `process.env` directly to spawnWithTimeout — always use `buildBeadEnv`
- NEVER include GITLAB_TOKEN in the args array or prompt string
- NEVER log the rendered prompt (may contain sensitive repo analysis)
  </action>
  <verify>
    <automated>cd /Users/julienderay/code/night-shift && npx tsc --noEmit</automated>
    <manual>Verify buildBeadEnv only includes GITLAB_TOKEN for "mr" bead</manual>
  </verify>
  <done>
    - buildBeadEnv returns minimal env without GITLAB_TOKEN for analyze/implement/verify beads
    - buildBeadEnv returns env WITH GITLAB_TOKEN only for mr bead
    - buildBeadArgs produces --allowedTools Bash Read Write as separate elements
    - runBead wraps spawnWithTimeout and returns BeadResult without throwing
    - No process.env spread anywhere in the module
  </done>
</task>

<task type="auto">
  <name>Task 2: Create code-agent-runner with 4-bead pipeline, retry, and fallback</name>
  <files>
    src/agent/code-agent-runner.ts
    tests/unit/code-agent-runner.test.ts
  </files>
  <action>
**1. Create `src/agent/code-agent-runner.ts`:**

This is the main pipeline orchestrator. It exports a single `runCodeAgentPipeline` function.

**Constants:**

```typescript
const FALLBACK_ORDER = ["tests", "refactoring", "docs", "security", "performance"] as const;
const MAX_IMPLEMENT_RETRIES = 2; // 3 total attempts (1 initial + 2 retries)
```

**Category guidance map:**

A `Record<string, string>` mapping category names to their locked guidance text from CONTEXT.md:
- tests: "Missing unit test coverage first, then improve existing test quality (better assertions, edge cases, flakiness reduction)"
- refactoring: "Broad scope — code duplication, complexity reduction, naming improvements, dead code removal, pattern consistency"
- docs: "Code-level documentation (comments, Scaladoc) first, then project-level docs (README, markdown files) if no code gaps found"
- security: "Active vulnerabilities first (OWASP-style: injection, auth bypass, insecure defaults, data exposure), then defensive hardening (input validation, secure error handling, safe logging)"
- performance: "Identify and address performance bottlenecks — inefficient algorithms, unnecessary allocations, suboptimal data structures, missing caching opportunities"

**`PipelineContext` interface:**

```typescript
interface PipelineContext {
  config: CodeAgentConfig;
  configDir: string;         // directory containing nightshift.yaml
  repoDir: string;           // cloned repo temp directory (cwd for beads)
  handoffDir: string;        // temp directory for JSON handoff files
  gitlabToken?: string;      // from env, forwarded only to MR bead
  timeoutMs: number;         // per-bead timeout
  logger: Logger;
}
```

**`buildBuiltInVars` function:**

Constructs the template variable map. Uses an explicit allowlist — NEVER spreads process.env:

```typescript
function buildBuiltInVars(
  config: CodeAgentConfig,
  category: string,
  categoryGuidance: string,
  handoffFile: string,
): Record<string, string> {
  return {
    category,
    category_guidance: categoryGuidance,
    repo_url: config.repoUrl,
    handoff_file: handoffFile,
    allowed_commands: config.allowedCommands.join(", "),
    reviewer: config.reviewer ?? "",
    ...config.variables,  // user-defined static vars only
  };
}
```

**`runAnalyzeBead` function:**

1. Compute handoff file path: `path.join(ctx.handoffDir, "analysis.json")`
2. Write a stub `{ "result": "NO_IMPROVEMENT", "reason": "pending" }` to the handoff file before spawning (safety net per Pitfall 3 from RESEARCH.md)
3. Build vars with `buildBuiltInVars`, set `handoff_file` to the analysis path
4. Load prompt via `loadBeadPrompt(ctx.config.prompts.analyze, vars, ctx.configDir)`
5. Run bead via `runBead({ beadName: "analyze", prompt, model: "claude-opus-4-6", cwd: ctx.repoDir, ... })`
6. Read and parse the handoff JSON file
7. Return `AnalysisResult`

**`runImplementBead` function:**

1. Build vars including `analysis_file` and `verify_error` (empty string on first attempt)
2. Load prompt, run bead with model `"claude-opus-4-6"`
3. Return BeadResult

**`runVerifyBead` function:**

1. Compute verify handoff file path
2. Write stub `{ "passed": false, "error_details": "pending" }` before spawning
3. Build vars with `handoff_file` set to verify path, include `build_commands` from allowed_commands that match build patterns
4. Load prompt, run bead with model `"claude-sonnet-4-6"`
5. Read and parse verify JSON
6. Return `{ passed: boolean, errorDetails: string }`

**`runMrBead` function:**

1. Build vars with `analysis_file`, `reviewer`, `category`, `short_description` (derived from analysis selected candidate)
2. Load prompt, run bead with model `"claude-sonnet-4-6"`
3. Pass `gitlabToken` to runBead — this is the ONLY bead that receives it
4. Parse stdout for MR URL (extract from claude JSON output result field)
5. Return MR URL string or undefined

**`runCodeAgentPipeline` main function:**

```typescript
export async function runCodeAgentPipeline(
  ctx: PipelineContext,
): Promise<CodeAgentRunResult> {
  const primaryCategory = resolveCategory(ctx.config.categorySchedule);
  if (!primaryCategory) {
    return { outcome: "NO_IMPROVEMENT", categoryUsed: "none", isFallback: false,
             reason: "No category scheduled for today", totalCostUsd: 0, totalDurationMs: 0 };
  }

  const categoriesToTry = [
    primaryCategory,
    ...FALLBACK_ORDER.filter(c => c !== primaryCategory),
  ];

  let totalCost = 0;
  let totalDuration = 0;
  const categoryReasons: Record<string, string> = {};

  for (const [index, category] of categoriesToTry.entries()) {
    const isFallback = index > 0;
    const guidance = CATEGORY_GUIDANCE[category] ?? category;

    // Analyze
    const analysis = await runAnalyzeBead(ctx, category, guidance);
    totalCost += analysis.cost;
    totalDuration += analysis.duration;

    if (analysis.result.result === "NO_IMPROVEMENT") {
      categoryReasons[category] = analysis.result.reason ?? "no improvement found";
      continue; // try next category
    }

    // Implement + Verify loop (up to 3 attempts)
    let verifyPassed = false;
    let lastError = "";
    for (let attempt = 0; attempt < MAX_IMPLEMENT_RETRIES + 1; attempt++) {
      // Reset repo to clean state before retry (not on first attempt)
      if (attempt > 0) {
        await resetRepo(ctx.repoDir);  // git reset --hard HEAD via spawnWithTimeout
      }

      const implResult = await runImplementBead(ctx, category, guidance, lastError);
      totalCost += implResult.costUsd;
      totalDuration += implResult.durationMs;

      const verifyResult = await runVerifyBead(ctx, category);
      totalCost += verifyResult.cost;
      totalDuration += verifyResult.duration;

      if (verifyResult.passed) {
        verifyPassed = true;
        break;
      }
      lastError = verifyResult.errorDetails;
    }

    if (!verifyPassed) {
      await resetRepo(ctx.repoDir);
      categoryReasons[category] = "verify failed after retries";
      continue; // try next category via fallback
    }

    // MR
    const actualCategory = isFallback
      ? `${category} (fallback from ${primaryCategory})`
      : category;
    const mrResult = await runMrBead(ctx, category, actualCategory);
    totalCost += mrResult.cost;
    totalDuration += mrResult.duration;

    return {
      outcome: "MR_CREATED",
      mrUrl: mrResult.mrUrl,
      categoryUsed: actualCategory,
      isFallback,
      totalCostUsd: totalCost,
      totalDurationMs: totalDuration,
    };
  }

  // All categories exhausted
  const summary = Object.entries(categoryReasons)
    .map(([cat, reason]) => `${cat}: ${reason}`)
    .join("; ");
  return {
    outcome: "NO_IMPROVEMENT",
    categoryUsed: primaryCategory,
    isFallback: false,
    reason: `All categories exhausted. ${summary}`,
    summary,
    totalCostUsd: totalCost,
    totalDurationMs: totalDuration,
  };
}
```

**`resetRepo` helper:**

Uses `spawnWithTimeout` to run `git reset --hard HEAD` in the repo directory. This clears failed Implement bead changes before retry (avoids Pitfall 6 from RESEARCH.md).

Import `resolveCategory` from `../daemon/scheduler.js`.

**2. Create `tests/unit/code-agent-runner.test.ts`:**

Mock `runBead` from `./bead-runner.js` and `loadBeadPrompt` from `./prompt-loader.js` using `vi.mock`. Mock `fs.readFile` for handoff JSON files. Mock `spawnWithTimeout` for `resetRepo`.

Test cases:
- **Happy path**: Analyze finds improvement, Implement succeeds, Verify passes, MR created — returns MR_CREATED with URL
- **NO_IMPROVEMENT primary + fallback success**: Primary category returns NO_IMPROVEMENT, second category finds improvement — returns MR_CREATED with isFallback=true and category notation "refactoring (fallback from tests)"
- **All categories exhausted**: Every Analyze bead returns NO_IMPROVEMENT — returns NO_IMPROVEMENT with summary of all category reasons
- **Verify fails then retries succeed**: First Verify fails, second attempt succeeds — returns MR_CREATED (verify attempt count = 2)
- **Verify fails 3 times, falls back**: All 3 Implement+Verify attempts fail for primary category, then next category succeeds — returns MR_CREATED with fallback
- **Token isolation**: Verify that runBead is called WITHOUT gitlabToken for analyze/implement/verify beads, and WITH gitlabToken only for mr bead
- **Git reset between retries**: Verify spawnWithTimeout called with `["git", "reset", "--hard", "HEAD"]` between retry attempts
- **No category scheduled**: resolveCategory returns undefined — returns NO_IMPROVEMENT immediately with "No category scheduled" reason
- **Notification category reflects fallback**: When fallback is used, categoryUsed includes "(fallback from X)" notation

Each test should verify the exact args passed to mocked functions to ensure security invariants hold.
  </action>
  <verify>
    <automated>cd /Users/julienderay/code/night-shift && npx vitest run tests/unit/code-agent-runner.test.ts --reporter=verbose</automated>
    <manual>Verify that GITLAB_TOKEN only appears in MR bead invocations in test assertions</manual>
  </verify>
  <done>
    - runCodeAgentPipeline returns MR_CREATED when full pipeline succeeds
    - runCodeAgentPipeline returns NO_IMPROVEMENT after trying all fallback categories
    - Category fallback order is: primary -> tests -> refactoring -> docs -> security -> performance (minus primary)
    - Implement bead retries up to 2 times after Verify failure (3 total attempts)
    - git reset --hard HEAD runs between Implement retries
    - GITLAB_TOKEN only forwarded to MR bead, not to other beads
    - categoryUsed includes "(fallback from X)" notation when fallback is used
    - All tests pass
  </done>
</task>

</tasks>

<verification>
- `npx vitest run tests/unit/code-agent-runner.test.ts` — all pipeline tests pass
- `npx tsc --noEmit` — no TypeScript errors across the project
- Verify buildBeadEnv only includes GITLAB_TOKEN for "mr" bead (grep source)
- Verify FALLBACK_ORDER matches CONTEXT.md: tests, refactoring, docs, security, performance
- Verify MAX_IMPLEMENT_RETRIES = 2 (3 total attempts)
- Verify resetRepo uses git reset --hard HEAD between retries
</verification>

<success_criteria>
- Complete 4-bead pipeline: Analyze -> Implement -> Verify -> MR
- GITLAB_TOKEN never leaks to non-MR beads (AGENT-08)
- NO_IMPROVEMENT returned after all fallback categories exhausted (AGENT-05)
- Retry logic resets repo state between attempts
- Pipeline cost and duration tracked across all bead invocations
- All tests pass, TypeScript compiles cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/03-agent-prompt-and-security/03-02-SUMMARY.md`
</output>
